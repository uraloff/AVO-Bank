import os
from pathlib import Path

from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from App.Core.Settings import settings


# DB_PATH = "E:\\MyCodes\\PythonCodes\\TelegramBots\\AVObank\\App\\Rag\\chroma_db"
BASE_DIR = Path(__file__).resolve().parents[2] 

# –¢–µ–ø–µ—Ä—å —Å—Ç—Ä–æ–∏–º –∂–µ–ª–µ–∑–æ–±–µ—Ç–æ–Ω–Ω—ã–µ –ø—É—Ç–∏
KB_PATH = os.path.join(BASE_DIR, "App", "Rag", "KnowledgeBase")
DB_PATH = os.path.join(BASE_DIR, "App", "Rag", "chroma_db")


class AVOBrain:
    def __init__(self):
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –≥–æ—Ç–æ–≤–æ–π –±–∞–∑–µ
        self.embedding_function = OpenAIEmbeddings(api_key=settings.AI_KEY)
        self.db = Chroma(persist_directory=DB_PATH, embedding_function=self.embedding_function)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        # temperature=0 ‚Äî –ö–†–ò–¢–ò–ß–ù–û –í–ê–ñ–ù–û –¥–ª—è –±–∞–Ω–∫–∞. –ù–∏–∫–∞–∫–æ–π —Ñ–∞–Ω—Ç–∞–∑–∏–∏.
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            api_key=settings.AI_KEY
        )

    async def get_answer(self, user_question: str):
        # 1. –ü–æ–∏—Å–∫: –∏—â–µ–º —á—É—Ç—å –±–æ–ª—å—à–µ –∫—É—Å–∫–æ–≤ (k=4 –∏–ª–∏ 5), —á—Ç–æ–±—ã –ø–æ–≤—ã—Å–∏—Ç—å —à–∞–Ω—Å—ã
        results = self.db.similarity_search_with_score(user_question, k=4)

        # –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ü–æ–¥–Ω–∏–º–∞–µ–º –ø–æ—Ä–æ–≥ –¥–æ 0.75 (–∏–ª–∏ –≤–æ–æ–±—â–µ —É–±–∏—Ä–∞–µ–º —Ñ–∏–ª—å—Ç—Ä –¥–ª—è —Ç–µ—Å—Ç–∞)
        # –î–∏—Å—Ç–∞–Ω—Ü–∏—è 0.75 –¥–ª—è OpenAI embeddings ‚Äî —ç—Ç–æ "–≤ —Ü–µ–ª–æ–º –ø—Ä–æ —Ç–æ –∂–µ —Å–∞–º–æ–µ".
        relevant_docs = [doc for doc, score in results if score < 0.75]

        if not relevant_docs:
            print("‚ùå –í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –ø–æ score!")
            return None 

        context_text = "\n\n---\n\n".join([doc.page_content for doc in relevant_docs])

        # 2. –£–ª—É—á—à–µ–Ω–Ω—ã–π –ü—Ä–æ–º–ø—Ç (English instructions + Russian content)
        # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Ä–∞–±–æ—Ç–∞—é—Ç –õ–£–ß–®–ï –¥–ª—è –º–æ–¥–µ–ª–µ–π GPT, 
        # —Ç–∞–∫ –∫–∞–∫ "–ø–æ–¥ –∫–∞–ø–æ—Ç–æ–º" –æ–Ω–∏ –¥—É–º–∞—é—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º.
        
        PROMPT_TEMPLATE = """
        You are an official AI assistant for AVO Bank. 
        Your goal is to answer client questions using the context provided below.

        üõ°Ô∏è SAFETY & BEHAVIOR RULES:
        1. **Core Truth:** Use ONLY the provided Context for banking facts (rates, limits, conditions).
        2. **Absurdity Check:** If the user asks something obviously wrong or absurd (e.g., "sell potatoes to get a card", "dance to open account"), politely REFUTE it using common sense, then state the ACTUAL rules from the Context.
        3. **No Hallucinations:** Do not invent new banking products or fees not listed in Context.
        4. **Retention:** If the user wants to leave/close account, add a retention message.

        üß† Context from Knowledge Base:
        {context}

        ---

        üó£ User Question: {question}
        """

        prompt = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
        messages = prompt.format_messages(context=context_text, question=user_question)

        response = self.llm.invoke(messages)
        answer_text = response.content

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ I_DONT_KNOW (–∏–Ω–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å —Ç–æ—á–∫—É –∏–ª–∏ –ø—Ä–æ–±–µ–ª)
        if "I_DONT_KNOW" in answer_text:
            return None

        return answer_text